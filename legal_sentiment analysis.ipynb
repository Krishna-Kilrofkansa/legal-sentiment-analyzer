{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.11",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.13",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "!pip install wget | tail -n 1\n!pip install scikit-learn | tail -n 1\n!pip install \"ibm-watson-machine-learning>=1.0.310\" | tail -n 1",
            "metadata": {
                "id": "062f74ad-7cd4-4eb9-864d-ab8278206ac9"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Successfully installed wget-3.2\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from lomond->ibm-watson-machine-learning>=1.0.310) (1.16.0)\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": "url = \"https://us-south.ml.cloud.ibm.com\"\napikey='VZFvE0ufR4ePXpSobgdtuBLMCQmBjxVuhnUD7aYC4osl'",
            "metadata": {
                "id": "195cb770-db46-4300-b802-4f586bc15279"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": "credentials = {\n    \"url\": url,\n    \"apikey\": apikey\n}",
            "metadata": {
                "id": "6262c9d5-9e9c-429b-add0-7c82481ea27b"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": "import os\n\ntry:\n    project_id = os.environ[\"PROJECT_ID\"]\nexcept KeyError:\n    project_id = input(\"Please enter your project_id (hit enter): \")\n\n\nproject_id",
            "metadata": {
                "id": "0209737f-01bd-4529-a1cb-52ae631a9225"
            },
            "outputs": [
                {
                    "execution_count": 5,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "'a100f552-8d74-4455-a7cb-bee0dba6ffd2'"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": "import  types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='VZFvE0ufR4ePXpSobgdtuBLMCQmBjxVuhnUD7aYC4osl',  # Your secret API key\n    ibm_auth_endpoint='https://iam.cloud.ibm.com/oidc/token',\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.us-south.cloud-object-storage.appdomain.cloud'\n)\n\nbucket = 'sentiment-analysislegal'\nobject_key = 'legal sentiment analyzer.csv'\n\nbody = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\nif not hasattr(body, \"iter\"):\n    body.iter = types.MethodType( iter, body)\ndata = pd.read_csv(body)\ndata.head(10)",
            "metadata": {
                "id": "f461fc0f-e2e0-499f-8017-71436fd702c5"
            },
            "outputs": [
                {
                    "execution_count": 6,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "   ID                                            Phrase  Sentiment\n0   1             The plaintiff's claims are dismissed.         -1\n1   2     The contract is deemed valid and enforceable.          1\n2   3        The appeal is denied due to lack of merit.         -1\n3   4     The legal team submitted additional evidence.          0\n4   5                The appeal is under consideration.          0\n5   6  The settlement agreement is fair and reasonable.          1\n6   7                The appeal is under consideration.          0\n7   8  The settlement agreement is fair and reasonable.          1\n8   9             The court reviewed the documentation.          0\n9  10     The contract is deemed valid and enforceable.          1",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>The plaintiff's claims are dismissed.</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>The contract is deemed valid and enforceable.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>The appeal is denied due to lack of merit.</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>The legal team submitted additional evidence.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>The appeal is under consideration.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>The settlement agreement is fair and reasonable.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>The appeal is under consideration.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>The settlement agreement is fair and reasonable.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>The court reviewed the documentation.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>The contract is deemed valid and enforceable.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": "lable_map={\n    -1:'negative',\n     0:'netural',\n     1: 'positive'\n}\ndata.value_counts(['Sentiment'])\n",
            "metadata": {
                "id": "29f08145-17aa-4b04-a60a-56f7832934f5"
            },
            "outputs": [
                {
                    "execution_count": 7,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "Sentiment\n 1           184\n-1           167\n 0           149\nName: count, dtype: int64"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\nimport pandas as pd\n\ndata_train, data_test, y_train, y_test = train_test_split(\n    data['Phrase'],\n    data['Sentiment'],\n    test_size=0.3,\n    random_state=33,\n    stratify=data['Sentiment']\n)\n\n# Convert to DataFrames\ndata_train = pd.DataFrame({'Phrase': data_train, 'Sentiment': y_train})\ndata_test = pd.DataFrame({'Phrase': data_test, 'Sentiment': y_test})\n",
            "metadata": {
                "id": "4061625e-6b5a-425c-b47e-e06e84a89d7e"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n\nprint([model.name for model in ModelTypes])",
            "metadata": {
                "id": "6964a5bb-dc48-4f07-b0ac-798b6c401c52"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "['FLAN_T5_XXL', 'FLAN_UL2', 'MT0_XXL', 'GPT_NEOX', 'MPT_7B_INSTRUCT2', 'STARCODER', 'LLAMA_2_70B_CHAT', 'LLAMA_2_13B_CHAT', 'GRANITE_13B_INSTRUCT', 'GRANITE_13B_CHAT', 'FLAN_T5_XL', 'GRANITE_13B_CHAT_V2', 'GRANITE_13B_INSTRUCT_V2', 'ELYZA_JAPANESE_LLAMA_2_7B_INSTRUCT', 'MIXTRAL_8X7B_INSTRUCT_V01_Q', 'CODELLAMA_34B_INSTRUCT_HF', 'GRANITE_20B_MULTILINGUAL']\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "code",
            "source": "model_id = ModelTypes.FLAN_T5_XXL\n",
            "metadata": {
                "id": "5332b938-3d0c-4174-b392-ef4c954dfecb"
            },
            "outputs": [],
            "execution_count": 10
        },
        {
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n\nparameters = {\n    GenParams.DECODING_METHOD: \"greedy\",\n    GenParams.RANDOM_SEED: 33,\n    GenParams.REPETITION_PENALTY: 1,\n    GenParams.MIN_NEW_TOKENS: 1,\n    GenParams.MAX_NEW_TOKENS: 1\n}",
            "metadata": {
                "id": "014cfeda-074f-4291-bb15-294dbc85de90"
            },
            "outputs": [],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": "from ibm_watson_machine_learning.foundation_models import Model\n\nmodel = Model(\n    model_id=model_id,\n    params=parameters,\n    credentials=credentials,\n    project_id=project_id\n)\n\nmodel.get_details()\n",
            "metadata": {
                "id": "e190ae18-00ba-49b6-9cdb-68e3a26998c8"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watson_machine_learning/foundation_models/utils/utils.py:273: LifecycleWarning: Model 'google/flan-t5-xxl' is in deprecated state from 2025-05-28 until 2025-07-30. IDs of alternative models: None. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n  warnings.warn(default_warning_template.format(\n",
                    "output_type": "stream"
                },
                {
                    "execution_count": 12,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "{'model_id': 'google/flan-t5-xxl',\n 'label': 'flan-t5-xxl-11b',\n 'provider': 'Google',\n 'source': 'Hugging Face',\n 'functions': [{'id': 'text_generation'}],\n 'short_description': 'flan-t5-xxl is an 11 billion parameter model based on the Flan-T5 family.',\n 'long_description': 'flan-t5-xxl (11B) is an 11 billion parameter model based on the Flan-T5 family. It is a pretrained T5 - an encoder-decoder model pre-trained on a mixture of supervised / unsupervised tasks converted into a text-to-text format, and fine-tuned on the Fine-tuned Language Net (FLAN) with instructions for better zero-shot and few-shot performance.',\n 'terms_url': 'https://huggingface.co/google/flan-t5-xxl/blob/main/README.md',\n 'input_tier': 'class_2',\n 'output_tier': 'class_2',\n 'number_params': '11b',\n 'min_shot_size': 0,\n 'task_ids': ['question_answering',\n  'summarization',\n  'retrieval_augmented_generation',\n  'classification',\n  'generation',\n  'extraction'],\n 'tasks': [{'id': 'question_answering', 'ratings': {'quality': 4}},\n  {'id': 'summarization', 'ratings': {'quality': 4}},\n  {'id': 'retrieval_augmented_generation', 'ratings': {'quality': 3}},\n  {'id': 'classification', 'ratings': {'quality': 4}},\n  {'id': 'generation'},\n  {'id': 'extraction', 'ratings': {'quality': 4}}],\n 'model_limits': {'max_sequence_length': 4096, 'max_output_tokens': 4095},\n 'limits': {'lite': {'call_time': '5m0s', 'max_output_tokens': 4095},\n  'v2-professional': {'call_time': '10m0s', 'max_output_tokens': 4095},\n  'v2-standard': {'call_time': '10m0s', 'max_output_tokens': 4095}},\n 'lifecycle': [{'id': 'available', 'start_date': '2023-07-07'},\n  {'id': 'deprecated', 'start_date': '2025-05-28'},\n  {'id': 'withdrawn', 'start_date': '2025-07-30'}]}"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "code",
            "source": "instruction = \"\"\"Determine the sentiment of the sentence.\nUse either 'positive', 'negative', 'neutral'. Use the provided examples as a template.\"\"\"",
            "metadata": {
                "id": "ed5f5432-e50d-4b14-963f-54ec0cf2df20"
            },
            "outputs": [],
            "execution_count": 13
        },
        {
            "cell_type": "code",
            "source": "zero_shot_inputs = [{\"input\": text} for text in data_test['Phrase']]\nfor i in range(2):\n    print(f\"The sentence example {i+1} is:\\n\\t {zero_shot_inputs[i]['input']}\\n\")",
            "metadata": {
                "id": "c9802150-aa3c-4047-ae6e-b1e0b32874ab"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "The sentence example 1 is:\n\t The legal team submitted additional evidence.\n\nThe sentence example 2 is:\n\t The appeal is denied due to lack of merit.\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 14
        },
        {
            "cell_type": "code",
            "source": "data_train_and_labels = data_train.copy()\ndata_train_and_labels['Sentiment'] = y_train\n",
            "metadata": {
                "id": "b27711fd-8abd-49fe-ab7f-dedb8edb93b0"
            },
            "outputs": [],
            "execution_count": 15
        },
        {
            "cell_type": "code",
            "source": "\nfew_shot_example = []\nfew_shot_examples = []\n\nfor phrase, sentiment in data_train_and_labels \\\n    .groupby('Sentiment') \\\n    .apply(lambda x: x.sample(2)).values:\n    \n    few_shot_example.append(f\"\\tsentence:\\t{phrase}\\n\\tsentiment: {sentiment}\\n\")\n\nfew_shot_examples = '\\n'.join(few_shot_example)",
            "metadata": {
                "id": "52f3c4c2-450f-442f-872d-b64ccab23b4f"
            },
            "outputs": [],
            "execution_count": 16
        },
        {
            "cell_type": "code",
            "source": "few_shot_inputs_ = [{\"input\": text} for text in data_test['Phrase'].values]\n\nfor i in range(2):\n    print(f\"The sentence example {i+1} is:\\n {few_shot_inputs_[i]['input']}\\n\")\n    print(f\"\\tSentiment: {y_test.iloc[i]}\\n\")\n",
            "metadata": {
                "id": "f2809e10-f916-42b2-88ac-0eabeeeddeb6"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "The sentence example 1 is:\n The legal team submitted additional evidence.\n\n\tSentiment: 0\n\nThe sentence example 2 is:\n The appeal is denied due to lack of merit.\n\n\tSentiment: -1\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 17
        },
        {
            "cell_type": "code",
            "source": "\nresults = []\nfor inp in few_shot_inputs_[:2]:\n    results.append(\n        model.generate(\" \".join([instruction + few_shot_examples[0], inp['input']]))[\"results\"][0]\n    )",
            "metadata": {
                "id": "53d305c8-4113-4777-852c-bd508ca61214"
            },
            "outputs": [],
            "execution_count": 18
        },
        {
            "cell_type": "code",
            "source": "import json\nprint(json.dumps(results, indent=2))\n",
            "metadata": {
                "id": "12ab0630-ea56-49c4-8c6d-f71757a820a0"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "[\n  {\n    \"generated_text\": \"neutral\",\n    \"generated_token_count\": 1,\n    \"input_token_count\": 42,\n    \"stop_reason\": \"max_tokens\"\n  },\n  {\n    \"generated_text\": \"negative\",\n    \"generated_token_count\": 1,\n    \"input_token_count\": 45,\n    \"stop_reason\": \"max_tokens\"\n  }\n]\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 19
        },
        {
            "cell_type": "code",
            "source": "from sklearn.metrics import classification_report\n\n# Assume `results` is your list of model outputs (len(results)=N)\nN = len(results)\n\n# 1. Re-build the true labels for just those N samples\ny_true_sub = [lable_map[lable] for lable in y_test.values[:N]]\n\n# 2. Extract your predictions\ny_pred = [r['generated_text'] for r in results]\n\n# 3. Sanity\u2010check lengths\nprint(f\"Length of y_true_sub: {len(y_true_sub)}\")\nprint(f\"Length of y_pred:      {len(y_pred)}\\n\")\n\n# 4. Generate the report\nprint(classification_report(y_true_sub, y_pred, zero_division=0))\n",
            "metadata": {
                "id": "4a5938ac-4a24-4d58-b0ee-a7e06ff0a2c1"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Length of y_true_sub: 2\nLength of y_pred:      2\n\n              precision    recall  f1-score   support\n\n    negative       1.00      1.00      1.00         1\n     netural       0.00      0.00      0.00         1\n     neutral       0.00      0.00      0.00         0\n\n    accuracy                           0.50         2\n   macro avg       0.33      0.33      0.33         2\nweighted avg       0.50      0.50      0.50         2\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 25
        },
        {
            "cell_type": "code",
            "source": "y_true = [lable_map[lable] for lable in y_test.values[:2]]\ny_true",
            "metadata": {
                "id": "d33c33aa-06f6-4b3c-b743-b0942b05bc37"
            },
            "outputs": [
                {
                    "execution_count": 20,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "['netural', 'negative']"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 20
        },
        {
            "cell_type": "code",
            "source": "y_pred = [result['generated_text'] for result in results]\ny_pred",
            "metadata": {
                "id": "dadea88e-7f60-47f1-a8aa-332787445417"
            },
            "outputs": [
                {
                    "execution_count": 21,
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": "['neutral', 'negative']"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 21
        },
        {
            "cell_type": "code",
            "source": "",
            "metadata": {
                "id": "2462b0ad-5e77-4577-8eae-5809151a8271"
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}